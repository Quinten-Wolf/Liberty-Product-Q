{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eratos_Forestry_Product.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install required packages"
      ],
      "metadata": {
        "id": "5Do6P1kGSysL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h_T9m2IbAvQc"
      },
      "outputs": [],
      "source": [
        "%%capture \n",
        "!pip install https://releases.eratos.com/sdk/python/eratos-python-latest.zip\n",
        "!pip install geopandas\n",
        "!pip install keplergl\n",
        "print('The Eratos SDK is installed')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import required packages"
      ],
      "metadata": {
        "id": "6vzNkCA1S4Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from eratos.creds import AccessTokenCreds\n",
        "from eratos.adapter import Adapter\n",
        "import geopandas as gpd\n",
        "from keplergl import KeplerGl\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import statistics\n",
        "from shapely.geometry import Polygon, box\n",
        "from shapely.strtree import STRtree\n",
        "import fiona\n",
        "import warnings\n",
        "import unicodedata\n",
        "import re\n",
        "import json\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7HRH0EseA-Vv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Update Client Folder Name"
      ],
      "metadata": {
        "id": "vuVwroLRTDb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "Client_Folder_Name = 'Bridgewood'\n",
        "\n",
        "\n",
        "\n",
        "ecreds = AccessTokenCreds(\n",
        "  'your key',\n",
        "  'your secret'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMgJQjNyZ_kL",
        "outputId": "fb7e5013-87fd-4e6a-88ef-38613d02440d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Run Product Code"
      ],
      "metadata": {
        "id": "bWbbYs2dTHt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Welcome to the Eratos Forestry Product\n",
        "#\n",
        "# Copyright (C) Eratos Group Pty Ltd and its affiliates.\n",
        "#\n",
        "# Please enter your Client Folder name, identical to the folder you created\n",
        "# and added the Client Property Geometry Files to, it is recommended to copy and paste it\n",
        "# in between the quotation marks below, to the right of the Client_Folder_Name\n",
        "# \n",
        "\n",
        "\n",
        "\n",
        "eadapter = Adapter(ecreds)\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def slugify(value, allow_unicode=False):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/django/django/blob/master/django/utils/text.py\n",
        "    Convert to ASCII if 'allow_unicode' is False. Convert spaces or repeated\n",
        "    dashes to single dashes. Remove characters that aren't alphanumerics,\n",
        "    underscores, or hyphens. Convert to lowercase. Also strip leading and\n",
        "    trailing whitespace, dashes, and underscores.\n",
        "    \"\"\"\n",
        "    value = str(value)\n",
        "    if allow_unicode:\n",
        "        value = unicodedata.normalize('NFKC', value)\n",
        "    else:\n",
        "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
        "    value = re.sub(r'[^\\w\\s-]', '', value.lower())\n",
        "    return re.sub(r'[-\\s]+', '-', value).strip('-_')\n",
        "\n",
        "print(slugify(Client_Folder_Name))\n",
        "\n",
        "slug_client_name = slugify(Client_Folder_Name)\n",
        "\n",
        "path =  '/content/gdrive/MyDrive/Eratos_Forestry_Product/Client_Files' + \"/\" + Client_Folder_Name\n",
        "\n",
        "\n",
        "#Maximum Temperature of Warmest Month\n",
        "burn_data = eadapter.Resource(ern='ern:e-pn.io:resource:eratos.blocks.modis.aumcd64a1')\n",
        "\n",
        "# Access the gridded dataset via the Gridded API:\n",
        "ds = burn_data.data().gapi()\n",
        "\n",
        "var = 'burndate'\n",
        "\n",
        "startTime = time.time()\n",
        "# list to store files\n",
        "geometry_files = []\n",
        "df_regions = pd.DataFrame()\n",
        "# Iterate directory\n",
        "for file in os.listdir(path):\n",
        "\n",
        "    if file.endswith('.kml'):\n",
        "        gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
        "        for layer in fiona.listlayers(path + \"/\" + file,):\n",
        "            \n",
        "            geo = gpd.read_file(path + \"/\" + file, layer=layer,driver='KML').to_crs(\"EPSG:4326\")\n",
        "            #geo = gpd.read_file(path + \"\\\\\" + file, driver='KML').to_crs(\"EPSG:4326\")\n",
        "            df_regions = df_regions.append(geo)\n",
        "        \n",
        "    if file.endswith('.shp'):\n",
        "        geo = gpd.read_file(path + \"/\" + file).to_crs(\"EPSG:4326\")\n",
        "        df_regions = df_regions.append(geo)\n",
        "\n",
        "\n",
        "poly_list = []\n",
        "\n",
        "#print(len(df_regions['geometry']))\n",
        "\n",
        "for geom in df_regions['geometry']:\n",
        "\n",
        "    bounds = geom.bounds\n",
        "    \n",
        "    minLon,minLat = bounds[0],bounds[1]\n",
        "    maxLon,maxLat = bounds[2],bounds[3]\n",
        "\n",
        "    lats = ds.get_subset_as_array('lat')\n",
        "    lons = ds.get_subset_as_array('lon')\n",
        "    spacingLat, spacingLon = lats[1]-lats[0], lons[1]-lons[0]\n",
        "\n",
        "    minLatIdx, maxLatIdx = np.argmin(np.abs(lats-minLat)), np.argmin(np.abs(lats-maxLat))+1\n",
        "    minLonIdx, maxLonIdx = np.argmin(np.abs(lons-minLon)), np.argmin(np.abs(lons-maxLon))+1\n",
        "    times = ds.get_subset_as_array('time')\n",
        "\n",
        "    if minLatIdx == maxLatIdx:\n",
        "        maxLatIdx += 1\n",
        "    if minLonIdx == maxLonIdx:\n",
        "        maxLonIdx += 1    \n",
        "\n",
        "    subLon = lons[minLonIdx:maxLonIdx]\n",
        "    subLat = lats[minLatIdx:maxLatIdx]\n",
        "    #x y y, x y y\n",
        "\n",
        "    for j in range(len(subLon)):\n",
        "        for k in range(len(subLat)):\n",
        "            lat = subLat[k]\n",
        "            lon = subLon[j]\n",
        "            \n",
        "            bottomLeftLat, bottomLeftLon = lat-0.5*spacingLat, lon-0.5*spacingLon\n",
        "            topRightLat, topRightLon = lat+0.5*spacingLat, lon+0.5*spacingLon\n",
        "            topLeftLat, topLeftLon = lat+0.5*spacingLat, lon-0.5*spacingLon\n",
        "            bottomRightLat, bottomRightLon = lat-0.5*spacingLat, lon+0.5*spacingLon\n",
        "            poly = Polygon([[topLeftLon, topLeftLat],[topRightLon, topRightLat],\n",
        "            [bottomRightLon, bottomRightLat],[bottomLeftLon, bottomLeftLat]])\n",
        "            \n",
        "            poly_list.append(poly)\n",
        "\n",
        "\n",
        "\n",
        "new_poly_list = []\n",
        "for poly in poly_list:\n",
        "    if poly not in new_poly_list: \n",
        "        new_poly_list.append(poly)\n",
        "\n",
        "regions_R_tree = STRtree(df_regions['geometry'].to_list())\n",
        "final_poly_list = []\n",
        "\n",
        "for poly in new_poly_list:\n",
        "    for geom in df_regions['geometry']:\n",
        "        if poly.intersects(geom):\n",
        "            final_poly_list.append(poly)\n",
        "\n",
        "\n",
        "final_property_gdf = gpd.GeoDataFrame(geometry=final_poly_list)   \n",
        "#print(len(final_poly_list))\n",
        "id = range(len(final_poly_list))\n",
        "final_property_gdf['id'] = id\n",
        "\n",
        "\n",
        "output_directory_path = r'/content/gdrive/MyDrive/Eratos_Forestry_Product/Outputs/'  + slug_client_name + \"_Outputs\"\n",
        "if os.path.exists(output_directory_path):\n",
        "    print('folder exists, writing file')\n",
        "else:\n",
        "     os.mkdir(output_directory_path)\n",
        "\n",
        "\n",
        "standardised_props_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'standardised_properties.geojson'\n",
        "final_property_gdf.to_file(standardised_props_name, driver='GeoJSON')\n",
        "\n",
        "grid_rate_25km = gpd.read_file('/content/gdrive/MyDrive/Eratos_Forestry_Product/Data_Files/grid_rate_25km_data_Q.geojson')\n",
        "id = range(len(grid_rate_25km['geometry']))\n",
        "grid_rate_25km['cell_id'] = id \n",
        "\n",
        "grid_rate_50km = gpd.read_file('/content/gdrive/MyDrive/Eratos_Forestry_Product/Data_Files/grid_rate_50km_data_Q.geojson')\n",
        "id = range(len(grid_rate_50km['geometry']))\n",
        "grid_rate_50km['cell_id'] = id \n",
        "\n",
        "grid_rate_100km = gpd.read_file('/content/gdrive/MyDrive/Eratos_Forestry_Product/Data_Files/grid_rate_100km_data_Q.geojson')\n",
        "id = range(len(grid_rate_100km['geometry']))\n",
        "grid_rate_100km['cell_id'] = id \n",
        "\n",
        "grid_rate_250km = gpd.read_file('/content/gdrive/MyDrive/Eratos_Forestry_Product/Data_Files/grid_rate_250km_data_Q.geojson')\n",
        "id = range(len(grid_rate_250km['geometry']))\n",
        "grid_rate_250km['cell_id'] = id \n",
        "\n",
        "tree_25 = STRtree(grid_rate_25km['geometry'])\n",
        "tree_50 = STRtree(grid_rate_50km['geometry'])\n",
        "tree_100 = STRtree(grid_rate_100km['geometry'])\n",
        "tree_250 = STRtree(grid_rate_250km['geometry'])\n",
        "\n",
        "tree_final = STRtree(final_property_gdf['geometry'])\n",
        "\n",
        "print(len(final_property_gdf['geometry']))\n",
        "t_len = len(final_property_gdf['geometry'])\n",
        "\n",
        "print(f'The script will take around {str(round((t_len*2.66)/60,0))} minutes' )\n",
        "\n",
        "grid_rate_25km_geom_np = grid_rate_25km['geometry'].to_numpy(dtype=None, copy=False)\n",
        "count_store_25km = np.zeros(len(grid_rate_25km['geometry']))\n",
        "\n",
        "grid_rate_50km_geom_np = grid_rate_50km['geometry'].to_numpy(dtype=None, copy=False)\n",
        "count_store_50km = np.zeros(len(grid_rate_50km['geometry']))\n",
        "\n",
        "grid_rate_100km_geom_np = grid_rate_100km['geometry'].to_numpy(dtype=None, copy=False)\n",
        "count_store_100km = np.zeros(len(grid_rate_100km['geometry']))\n",
        "\n",
        "grid_rate_250km_geom_np = grid_rate_250km['geometry'].to_numpy(dtype=None, copy=False)\n",
        "count_store_250km = np.zeros(len(grid_rate_250km['geometry']))\n",
        "\n",
        "for Pindex, Prow in final_property_gdf.iterrows():\n",
        "    geom = Prow['geometry']\n",
        "    str_tree = tree_25.query(geom)\n",
        "    ##25\n",
        "    for cell in str_tree:\n",
        "        result = np.where(grid_rate_25km_geom_np == cell)\n",
        "        count_store_25km[result] += 1/len(str_tree)\n",
        "    ##50    \n",
        "    str_tree = tree_50.query(geom)\n",
        "    \n",
        "    for cell in str_tree:\n",
        "        result = np.where(grid_rate_50km_geom_np == cell)\n",
        "        count_store_50km[result] += 1/len(str_tree)\n",
        "    ##100    \n",
        "    str_tree = tree_100.query(geom)\n",
        "    \n",
        "    for cell in str_tree:\n",
        "        result = np.where(grid_rate_100km_geom_np == cell)\n",
        "        count_store_100km[result] += 1/len(str_tree)\n",
        "\n",
        "    ##250    \n",
        "    str_tree = tree_250.query(geom)\n",
        "    \n",
        "    for cell in str_tree:\n",
        "        result = np.where(grid_rate_250km_geom_np == cell)\n",
        "        count_store_250km[result] += 1/len(str_tree)\n",
        "\n",
        "grid_rate_25km['portfolio_count'] = count_store_25km\n",
        "grid_rate_50km['portfolio_count'] = count_store_50km\n",
        "grid_rate_100km['portfolio_count'] = count_store_100km\n",
        "grid_rate_250km['portfolio_count'] = count_store_250km\n",
        "\n",
        "df_portfolio_risk_25 = grid_rate_25km.loc[grid_rate_25km['portfolio_count'] > 0]\n",
        "df_portfolio_risk_50 = grid_rate_50km.loc[grid_rate_50km['portfolio_count'] > 0]\n",
        "df_portfolio_risk_100 = grid_rate_100km.loc[grid_rate_100km['portfolio_count'] > 0]\n",
        "df_portfolio_risk_250 = grid_rate_250km.loc[grid_rate_250km['portfolio_count'] > 0]\n",
        "\n",
        "# risk_25_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'portfolio_risk_25km.geojson'\n",
        "# risk_50_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'portfolio_risk_50km.geojson'\n",
        "# risk_100_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'portfolio_risk_100km.geojson'\n",
        "# risk_250_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'portfolio_risk_250km.geojson'\n",
        "\n",
        "\n",
        "# df_portfolio_risk_25.to_file(risk_25_name, driver='GeoJSON')\n",
        "# df_portfolio_risk_50.to_file(risk_50_name, driver='GeoJSON')\n",
        "# df_portfolio_risk_100.to_file(risk_100_name, driver='GeoJSON')\n",
        "# df_portfolio_risk_250.to_file(risk_250_name, driver='GeoJSON')\n",
        "\n",
        "\n",
        "final_stats_data_list = [df_portfolio_risk_25,df_portfolio_risk_50,df_portfolio_risk_100,df_portfolio_risk_250]\n",
        "\n",
        "name = ['25km','50km','100km','250km']\n",
        "weight_area_mean_rate_final = []\n",
        "max_max_rate_final = []\n",
        "mean_rate_final = []\n",
        "\n",
        "\n",
        "for data in final_stats_data_list:\n",
        "    total_portfolio_cells = data['portfolio_count'].sum()\n",
        "    proportion_list = [] \n",
        "    for val in data['portfolio_count']:\n",
        "        proportion_list.append(val/total_portfolio_cells)\n",
        "    data['Weighted Influence (Area)'] = proportion_list\n",
        "    weight_area_mean_rate = [a * b for a, b in zip(proportion_list, data['mean_grid_burn_rate'])]\n",
        "\n",
        "    weight_area_mean_rate_final.append(sum(weight_area_mean_rate))\n",
        "    max_max_rate_final.append(max(data['max_grid_burn_rate']))\n",
        "    mean_rate_final.append(statistics.mean(data['mean_grid_burn_rate']))\n",
        "    \n",
        "\n",
        "portfolio_rates_25_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'portfolio_rates_25km.csv'\n",
        "portfolio_rates_50_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'portfolio_rates_50km.csv'\n",
        "portfolio_rates_100_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'portfolio_rates_100km.csv'\n",
        "portfolio_rates_250_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'portfolio_rates_250km.csv'\n",
        "\n",
        "\n",
        "# final_stats_data_list[0].to_csv(portfolio_rates_25_name)   \n",
        "# final_stats_data_list[1].to_csv(portfolio_rates_50_name)   \n",
        "# final_stats_data_list[2].to_csv(portfolio_rates_100_name)   \n",
        "# final_stats_data_list[3].to_csv(portfolio_rates_250_name)\n",
        "\n",
        "\n",
        "final_output_df = pd.DataFrame()\n",
        "\n",
        "final_output_df['grid'] = name\n",
        "final_output_df['weight_area_mean_rate_final'] = weight_area_mean_rate_final\n",
        "final_output_df['mean_rate_final'] = mean_rate_final\n",
        "final_output_df['max_max_rate_final'] = max_max_rate_final\n",
        "\n",
        "final_portfolio_rates_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'final_portfolio_rates.csv'\n",
        "\n",
        "final_output_df.to_csv(final_portfolio_rates_name)   \n",
        "\n",
        "\n",
        "with pd.ExcelWriter(output_directory_path + \"\\\\\" +  slug_client_name + '_' + 'Full_portfolio_rates.xlsx') as writer:  \n",
        "    final_output_df.to_excel(writer, sheet_name='Rates_Summary')\n",
        "    final_stats_data_list[0].to_excel(writer, sheet_name='portfolio_rates_25km')\n",
        "    final_stats_data_list[1].to_excel(writer, sheet_name='portfolio_rates_50km')\n",
        "    final_stats_data_list[2].to_excel(writer, sheet_name='portfolio_rates_100km')\n",
        "    final_stats_data_list[3].to_excel(writer, sheet_name='portfolio_rates_250km')\n",
        "\n",
        "\n",
        "f = open('/content/gdrive/MyDrive/Eratos_Forestry_Product/Scripts & Supporting/kepler_map_Liberty_config.json')\n",
        "\n",
        "config = json.load(f)\n",
        "\n",
        "f.close()\n",
        "\n",
        "kepler_map_Liberty = KeplerGl(height = 1200,config=config)\n",
        "kepler_map_Liberty.add_data(data=df_regions,name=\"Original_Properties\")\n",
        "kepler_map_Liberty.add_data(data=final_property_gdf,name=\"Standardised_Properties\")\n",
        "kepler_map_Liberty.add_data(data=final_stats_data_list[0],name=\"25km_cells\")\n",
        "kepler_map_Liberty.add_data(data=final_stats_data_list[1],name=\"50km_cells\")\n",
        "kepler_map_Liberty.add_data(data=final_stats_data_list[2],name=\"100km_cells\")\n",
        "kepler_map_Liberty.add_data(data=final_stats_data_list[3],name=\"250km_cells\")\n",
        "\n",
        "\n",
        "final_kepler_name = output_directory_path + \"\\\\\" +  slug_client_name + '_' +   'final_kepler.html'\n",
        "\n",
        "kepler_map_Liberty.save_to_html(file_name=final_kepler_name,config=config)\n",
        "\n",
        "executionTime = (time.time() - startTime)\n",
        "print('Execution time in seconds: ' + str(executionTime))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m63XLonAA-o0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}